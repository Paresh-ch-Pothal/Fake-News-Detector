{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc7d19e-80ca-42ae-9a79-4a0c359eb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563b281d-ff0d-4173-a38a-618bb041e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e513bc67-5cf2-47b6-8c06-2261ce35de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"Fake or True News Detection Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b136d9e-84a2-4f7d-80fe-1c782b2229d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in d:\\anaconda\\envs\\tfenv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\envs\\tfenv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\tfenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed joblib-1.5.1 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7110c4d-dc81-4618-a6e4-b8705c4d1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pares\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244be7c9-e926-4224-a03c-b960cb72b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_remove_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0370dcd-9e84-43d5-aef3-b2c7f307a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2607d9-f5c0-422b-91d8-e3e44670dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "def func(text):\n",
    "  cleaned_text = clean_and_remove_stopwords(text)\n",
    "  input_text = tokenizer.texts_to_sequences([cleaned_text])\n",
    "  input_text_pad = pad_sequences(input_text,maxlen=maxlen)\n",
    "  res = model.predict(input_text_pad)\n",
    "  label = \"True News\" if res[0][1] > res[0][0] else \"False News\"\n",
    "  confidence = round(float(max(res[0])), 4) * 100\n",
    "  return f\"{label} (Confidence: {confidence})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1fa80f-826a-45dd-a02a-e18eaf68eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95a9a13-80f0-48fd-9116-af23981e49bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://9a8a7d25158e66a4d6.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9a8a7d25158e66a4d6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=func,\n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter news text here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Fake News Detector\",\n",
    "    description=\"Paste any news article or headline to check if it's real or fake.\"\n",
    ")\n",
    "\n",
    "# Launch in notebook\n",
    "iface.launch(inline=True,share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62ddf-5a17-493a-803a-7153a709574a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
